{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14cbb4c5",
   "metadata": {},
   "source": [
    "### Version simple (compter le nombre de mots de l'offre dans le CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4a0eebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\eupho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "from docx import Document\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# T√©l√©chargement des stopwords fran√ßais si n√©cessaire\n",
    "nltk.download('stopwords')\n",
    "stop_fr = set(stopwords.words('french'))\n",
    "\n",
    "def lire_docx(path):\n",
    "    \"\"\"Extrait le texte brut d'un fichier Word (.docx).\"\"\"\n",
    "    doc = Document(path)\n",
    "    full_text = [p.text for p in doc.paragraphs]\n",
    "    return \"\\n\".join(full_text)\n",
    "\n",
    "# --- Nettoyage de texte ---\n",
    "def nettoyer_texte(texte: str) -> str:\n",
    "    \"\"\"Met en minuscules et supprime caract√®res sp√©ciaux.\"\"\"\n",
    "    texte = texte.lower()\n",
    "    texte = re.sub(r\"[^a-z√†√¢√ß√©√®√™√´√Æ√Ø√¥√ª√π√º√ø√±√¶≈ì0-9\\s]\", \" \", texte)\n",
    "    texte = re.sub(r\"\\s+\", \" \", texte)\n",
    "    return texte.strip()\n",
    "\n",
    "# --- Extraction des mots cl√©s d'une offre (stop words exclus) ---\n",
    "def extraire_mots_cles_offre(offre_text: str):\n",
    "    \"\"\"\n",
    "    Retourne la liste des mots cl√©s uniques de l'offre apr√®s nettoyage\n",
    "    et suppression des stop words fran√ßais.\n",
    "    \"\"\"\n",
    "    texte = nettoyer_texte(offre_text)\n",
    "    mots = texte.split()\n",
    "    # Exclusion des stop words\n",
    "    mots_cles = [mot for mot in mots if mot not in stop_fr]\n",
    "    return list(set(mots_cles))  # mots uniques\n",
    "\n",
    "# --- Score de correspondance CV vs offre ---\n",
    "def score_cv_offre(cv_text: str, offre_text: str):\n",
    "    \"\"\"\n",
    "    Calcule un score de correspondance CV vs offre bas√© √† la fois sur la pr√©sence \n",
    "    et la fr√©quence des mots-cl√©s de l'offre dans le CV.\n",
    "\n",
    "    Contrairement √† la version simple, cette fonction prend en compte plusieurs \n",
    "    occurrences d'un mot-cl√© dans le CV tout en limitant l'impact d'un mot tr√®s \n",
    "    r√©p√©t√© gr√¢ce √† `max_occurrences`.\n",
    "\n",
    "    Algorithme :\n",
    "    1. Nettoyage du texte du CV (minuscules, suppression de ponctuation, etc.).\n",
    "    2. S√©paration du texte en mots et comptage des occurrences de chaque mot via Counter.\n",
    "    3. Extraction des mots-cl√©s uniques de l'offre (apr√®s nettoyage).\n",
    "    4. Pour chaque mot-cl√© de l'offre, ajouter au score le nombre d‚Äôoccurrences \n",
    "       pr√©sentes dans le CV, limit√© par `max_occurrences` pour √©viter qu‚Äôun mot\n",
    "       unique r√©p√©t√© 100 fois domine le score.\n",
    "    5. Normalisation : le score total est divis√© par le score maximum possible \n",
    "       (nombre de mots-cl√©s * max_occurrences) pour obtenir un pourcentage.\n",
    "    \n",
    "    Arguments :\n",
    "    - cv_text (str) : texte complet du CV.\n",
    "    - offre_text (str) : texte complet de l'offre.\n",
    "    - max_occurrences (int, optionnel) : nombre maximal d‚Äôoccurrences par mot-cl√©\n",
    "      comptabilis√©es pour le score (d√©faut 2).\n",
    "\n",
    "    Retour :\n",
    "    - score_pct (float) : pourcentage de correspondance entre le CV et l'offre, \n",
    "      bas√© sur la diversit√© et la fr√©quence des mots-cl√©s.\n",
    "\n",
    "    Exemple :\n",
    "    >>> score_cv_frequence(cv_text, offre_text)\n",
    "    62.5\n",
    "    \"\"\"\n",
    "    cv_clean = nettoyer_texte(cv_text)\n",
    "    cv_mots = set(cv_clean.split())\n",
    "\n",
    "    mots_cles = extraire_mots_cles_offre(offre_text)\n",
    "    # print(\"mots_cles:\", mots_cles)\n",
    "\n",
    "    nb_trouves = sum(1 for mot in mots_cles if mot in cv_mots)\n",
    "    Score = nb_trouves / len(mots_cles) if mots_cles else 0\n",
    "\n",
    "    return Score * 100  # Score en pourcentage\n",
    "\n",
    "def score_cv_frequence(cv_text: str, offre_text: str, max_occurrences=2):\n",
    "    \"\"\"\n",
    "    Score bas√© sur la pr√©sence et la fr√©quence des mots-cl√©s contrairement √†\n",
    "    la fonction pr√©cedente.\n",
    "    max_occurrences limite l'impact d'un mot r√©p√©t√©.\n",
    "    \"\"\"\n",
    "    cv_clean = nettoyer_texte(cv_text)\n",
    "    cv_mots = cv_clean.split()\n",
    "    cv_counts = Counter(cv_mots)\n",
    "\n",
    "    mots_cles = extraire_mots_cles_offre(offre_text)\n",
    "\n",
    "    score_total = 0\n",
    "    for mot in mots_cles:\n",
    "        score_total += min(cv_counts.get(mot, 0), max_occurrences)\n",
    "\n",
    "    max_score = len(mots_cles) * max_occurrences\n",
    "    score_pct = (score_total / max_score) * 100 if max_score > 0 else 0\n",
    "\n",
    "    return score_pct\n",
    "\n",
    "offre = \"\"\"\n",
    "Dans le cadre de sa mission d‚Äôexploitation et de valorisation des donn√©es m√©dicales, la DIDM fait face √† un besoin croissant de donn√©es fiables. C‚Äôest pourquoi un nouveau poste est cr√©√©.\n",
    "Vous viendrez compl√©ter une √©quipe compos√©e d‚Äôune Charg√©e d‚Äô√©tudes et d√©veloppements √† 50 % et d‚Äôun Responsable Etudes et D√©veloppements. Sous la responsabilit√© de ce dernier, vos missions seront les suivantes :\n",
    "Construire des pipelines de donn√©es pour alimenter la BI et l‚Äôanalytique.\n",
    "Mod√©liser et structurer les flux, tables et sch√©mas\n",
    "Garantir la qualit√©, la fiabilit√© et la s√©curit√© des donn√©es\n",
    "D√©velopper de nouveaux datasets pour la BI de la DIDM\n",
    "Mettre en place des standards de d√©veloppement et de bonnes pratiques\n",
    "Assurer le support et la r√©solution des incidents sur votre p√©rim√®tre...\n",
    "\n",
    "Votre bo√Æte √† outils\n",
    "Excellente ma√Ætrise de SQL (Oracle) et solide exp√©rience en R\n",
    "Connaissances en Julia, Java ou Scala appr√©ci√©es\n",
    "Pratique des outils de versioning (Git, Bitbucket, Github)\n",
    "Exp√©rience avec un outil ETL, id√©alement Talend\n",
    "Une premi√®re approche de la dataviz (Tableau, QlikView) est un atout\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef3eb6d",
   "metadata": {},
   "source": [
    "#### Crit√®res = pr√©sence ou absence de mot-cl√© (osef de la fr√©quence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9611db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score de correspondance : 46.6 %\n"
     ]
    }
   ],
   "source": [
    "# Test sur un CV individuel\n",
    "# Lis un CV .docx\n",
    "cv_text = lire_docx(\"test.docx\")\n",
    "\n",
    "Score = score_cv_offre(cv_text, offre)\n",
    "print(f\"Score de correspondance : {Score:.1f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb45c63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score de correspondance pour CV - Laurent D._14_01_2024.docx : 42.0 %\n",
      "Score de correspondance pour CV_AnaA_20250226.docx : 31.8 %\n",
      "Score de correspondance pour CV_CSA_NRJBI_20251016.docx : 28.4 %\n",
      "Score de correspondance pour NRJBI_CEC_CV_Senior.docx : 17.0 %\n",
      "Score de correspondance pour NRJBI_CEC_CV_Senior_data_engineer_gemini-2.0-flash_enhanced.docx : 9.1 %\n",
      "Score de correspondance pour NRJBI_CEC_CV_Senior_data_engineer_gemini-2.5-flash-lite_enhanced.docx : 20.5 %\n",
      "Score de correspondance pour NRJBI_CEC_CV_Senior_data_engineer_gemini-2.5-flash_enhanced.docx : 29.5 %\n",
      "Score de correspondance pour NRJBI_CEC_CV_Senior_data_engineer_gemini-2.5-pro_enhanced.docx : 39.8 %\n",
      "Score de correspondance pour NRJBI_CV_EMO_202510_revisionElise.docx : 23.9 %\n",
      "Score de correspondance pour NRJBI_ERE_CV - 20250930.docx : 35.2 %\n",
      "Score de correspondance pour NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-flash-lite_enhanced.docx : 34.1 %\n",
      "Score de correspondance pour NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-flash_enhanced.docx : 37.5 %\n",
      "Score de correspondance pour NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-flash_enhanced_surligne.docx : 37.5 %\n",
      "Score de correspondance pour NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-pro_enhanced.docx : 38.6 %\n",
      "Score de correspondance pour test.docx : 46.6 %\n"
     ]
    }
   ],
   "source": [
    "# Test sur plusieurs CV \n",
    "# Faire une boucle sur les CV dans le dossier CVs\n",
    "dossier_cvs = \"CVs\"\n",
    "all_scores = {}\n",
    "for nom_fichier in os.listdir(dossier_cvs):\n",
    "    # Lis un CV .docx\n",
    "    cv_text = lire_docx(f\"./{dossier_cvs}/{nom_fichier}\")\n",
    "\n",
    "    Score = score_cv_offre(cv_text, offre)\n",
    "    all_scores[nom_fichier] = Score\n",
    "    print(f\"Score de correspondance pour {nom_fichier} : {Score:.1f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773176df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fichier</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>test.docx</td>\n",
       "      <td>46.590909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CV - Laurent D._14_01_2024.docx</td>\n",
       "      <td>42.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NRJBI_CEC_CV_Senior_data_engineer_gemini-2.5-pro_enhanced.docx</td>\n",
       "      <td>39.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-pro_enhanced.docx</td>\n",
       "      <td>38.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-flash_enhanced.docx</td>\n",
       "      <td>37.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-flash_enhanced_surligne.docx</td>\n",
       "      <td>37.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NRJBI_ERE_CV - 20250930.docx</td>\n",
       "      <td>35.227273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-flash-lite_enhanced.docx</td>\n",
       "      <td>34.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CV_AnaA_20250226.docx</td>\n",
       "      <td>31.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NRJBI_CEC_CV_Senior_data_engineer_gemini-2.5-flash_enhanced.docx</td>\n",
       "      <td>29.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CV_CSA_NRJBI_20251016.docx</td>\n",
       "      <td>28.409091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NRJBI_CV_EMO_202510_revisionElise.docx</td>\n",
       "      <td>23.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NRJBI_CEC_CV_Senior_data_engineer_gemini-2.5-flash-lite_enhanced.docx</td>\n",
       "      <td>20.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRJBI_CEC_CV_Senior.docx</td>\n",
       "      <td>17.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRJBI_CEC_CV_Senior_data_engineer_gemini-2.0-flash_enhanced.docx</td>\n",
       "      <td>9.090909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          Fichier  \\\n",
       "14                                                                      test.docx   \n",
       "0                                                 CV - Laurent D._14_01_2024.docx   \n",
       "7                  NRJBI_CEC_CV_Senior_data_engineer_gemini-2.5-pro_enhanced.docx   \n",
       "13             NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-pro_enhanced.docx   \n",
       "11           NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-flash_enhanced.docx   \n",
       "12  NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-flash_enhanced_surligne.docx   \n",
       "9                                                    NRJBI_ERE_CV - 20250930.docx   \n",
       "10      NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-flash-lite_enhanced.docx   \n",
       "1                                                           CV_AnaA_20250226.docx   \n",
       "6                NRJBI_CEC_CV_Senior_data_engineer_gemini-2.5-flash_enhanced.docx   \n",
       "2                                                      CV_CSA_NRJBI_20251016.docx   \n",
       "8                                          NRJBI_CV_EMO_202510_revisionElise.docx   \n",
       "5           NRJBI_CEC_CV_Senior_data_engineer_gemini-2.5-flash-lite_enhanced.docx   \n",
       "3                                                        NRJBI_CEC_CV_Senior.docx   \n",
       "4                NRJBI_CEC_CV_Senior_data_engineer_gemini-2.0-flash_enhanced.docx   \n",
       "\n",
       "        Score  \n",
       "14  46.590909  \n",
       "0   42.045455  \n",
       "7   39.772727  \n",
       "13  38.636364  \n",
       "11  37.500000  \n",
       "12  37.500000  \n",
       "9   35.227273  \n",
       "10  34.090909  \n",
       "1   31.818182  \n",
       "6   29.545455  \n",
       "2   28.409091  \n",
       "8   23.863636  \n",
       "5   20.454545  \n",
       "3   17.045455  \n",
       "4    9.090909  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertir all_scores en DataFrame pandas pour analyse ult√©rieure\n",
    "df_scores = pd.DataFrame(list(all_scores.items()), columns=['Fichier', 'Score'])\n",
    "\n",
    "# Tri par ordre croissant du Score\n",
    "df_scores = df_scores.sort_values(by='Score', ascending=False)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4db331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fichier</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CV - Laurent D._14_01_2024.docx</td>\n",
       "      <td>42.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CV_AnaA_20250226.docx</td>\n",
       "      <td>31.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CV_CSA_NRJBI_20251016.docx</td>\n",
       "      <td>28.409091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRJBI_CEC_CV_Senior.docx</td>\n",
       "      <td>17.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRJBI_CEC_CV_Senior_data_engineer_gemini-2.0-flash_enhanced.docx</td>\n",
       "      <td>9.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NRJBI_CEC_CV_Senior_data_engineer_gemini-2.5-flash-lite_enhanced.docx</td>\n",
       "      <td>20.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NRJBI_CEC_CV_Senior_data_engineer_gemini-2.5-flash_enhanced.docx</td>\n",
       "      <td>29.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NRJBI_CEC_CV_Senior_data_engineer_gemini-2.5-pro_enhanced.docx</td>\n",
       "      <td>39.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NRJBI_CV_EMO_202510_revisionElise.docx</td>\n",
       "      <td>23.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NRJBI_ERE_CV - 20250930.docx</td>\n",
       "      <td>35.227273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-flash-lite_enhanced.docx</td>\n",
       "      <td>34.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-flash_enhanced.docx</td>\n",
       "      <td>37.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-flash_enhanced_surligne.docx</td>\n",
       "      <td>37.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-pro_enhanced.docx</td>\n",
       "      <td>38.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>test.docx</td>\n",
       "      <td>46.590909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          Fichier  \\\n",
       "0                                                 CV - Laurent D._14_01_2024.docx   \n",
       "1                                                           CV_AnaA_20250226.docx   \n",
       "2                                                      CV_CSA_NRJBI_20251016.docx   \n",
       "3                                                        NRJBI_CEC_CV_Senior.docx   \n",
       "4                NRJBI_CEC_CV_Senior_data_engineer_gemini-2.0-flash_enhanced.docx   \n",
       "5           NRJBI_CEC_CV_Senior_data_engineer_gemini-2.5-flash-lite_enhanced.docx   \n",
       "6                NRJBI_CEC_CV_Senior_data_engineer_gemini-2.5-flash_enhanced.docx   \n",
       "7                  NRJBI_CEC_CV_Senior_data_engineer_gemini-2.5-pro_enhanced.docx   \n",
       "8                                          NRJBI_CV_EMO_202510_revisionElise.docx   \n",
       "9                                                    NRJBI_ERE_CV - 20250930.docx   \n",
       "10      NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-flash-lite_enhanced.docx   \n",
       "11           NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-flash_enhanced.docx   \n",
       "12  NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-flash_enhanced_surligne.docx   \n",
       "13             NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-pro_enhanced.docx   \n",
       "14                                                                      test.docx   \n",
       "\n",
       "        Score  \n",
       "0   42.045455  \n",
       "1   31.818182  \n",
       "2   28.409091  \n",
       "3   17.045455  \n",
       "4    9.090909  \n",
       "5   20.454545  \n",
       "6   29.545455  \n",
       "7   39.772727  \n",
       "8   23.863636  \n",
       "9   35.227273  \n",
       "10  34.090909  \n",
       "11  37.500000  \n",
       "12  37.500000  \n",
       "13  38.636364  \n",
       "14  46.590909  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tri par ordre alphab√©tique des fichiers\n",
    "df_scores = df_scores.sort_values(by='Fichier', ascending=True)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e629bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ CV - Laurent D._14_01_2024.docx\n",
      "   CV - Laurent D._14_01_2024.docx                                                   42.05 (nan)\n",
      "\n",
      "üìÑ CV_AnaA_20250226.docx\n",
      "   CV_AnaA_20250226.docx                                                             31.82 (nan)\n",
      "\n",
      "üìÑ CV_CSA_NRJBI_20251016.docx\n",
      "   CV_CSA_NRJBI_20251016.docx                                                        28.41 (nan)\n",
      "\n",
      "üìÑ NRJBI_CEC_CV_Senior.docx\n",
      "   NRJBI_CEC_CV_Senior.docx                                                          17.05 (0.00)\n",
      "   NRJBI_CEC_CV_Senior_data_engineer_gemini-2.5-pro_enhanced.docx                    39.77 (+22.73)\n",
      "   NRJBI_CEC_CV_Senior_data_engineer_gemini-2.5-flash_enhanced.docx                  29.55 (+12.50)\n",
      "   NRJBI_CEC_CV_Senior_data_engineer_gemini-2.5-flash-lite_enhanced.docx             20.45 (+3.41)\n",
      "   NRJBI_CEC_CV_Senior_data_engineer_gemini-2.0-flash_enhanced.docx                   9.09 (-7.95)\n",
      "\n",
      "üìÑ NRJBI_CV_EMO_202510_revisionElise.docx\n",
      "   NRJBI_CV_EMO_202510_revisionElise.docx                                            23.86 (0.00)\n",
      "\n",
      "üìÑ NRJBI_ERE_CV - 20250930.docx\n",
      "   NRJBI_ERE_CV - 20250930.docx                                                      35.23 (0.00)\n",
      "   NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-pro_enhanced.docx                38.64 (+3.41)\n",
      "   NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-flash_enhanced.docx              37.50 (+2.27)\n",
      "   NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-flash_enhanced_surligne.docx     37.50 (+2.27)\n",
      "   NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-flash-lite_enhanced.docx         34.09 (-1.14)\n",
      "\n",
      "üìÑ test.docx\n",
      "   test.docx                                                                         46.59 (nan)\n"
     ]
    }
   ],
   "source": [
    "# Affichage par ordre croissant pour chaque groupe de CVs communs (CV original + CV am√©lior√©s)\n",
    "# Liste connue des fichiers originaux\n",
    "original_files = [\n",
    "    \"NRJBI_CEC_CV_Senior.docx\",\n",
    "    \"NRJBI_ERE_CV - 20250930.docx\",\n",
    "    \"NRJBI_CV_EMO_202510_revisionElise.docx\",\n",
    "]\n",
    "\n",
    "# Extraire juste le nom sans extension pour faciliter la recherche\n",
    "original_bases = [f.rsplit('.', 1)[0] for f in original_files]\n",
    "\n",
    "# Trouver √† quel original correspond chaque fichier\n",
    "def find_base(Fichier):\n",
    "    for base in original_bases:\n",
    "        if Fichier.startswith(base):  # on compare le d√©but du nom\n",
    "            return base\n",
    "    return Fichier  # si aucun match, on garde le nom lui-m√™me\n",
    "\n",
    "df_scores[\"base_name\"] = df_scores[\"Fichier\"].apply(find_base)\n",
    "\n",
    "# S'il manque l'extension .docx dans base_name, on l'ajoute pour correspondre aux cl√©s originales\n",
    "df_scores[\"base_name\"] = df_scores[\"base_name\"].apply(lambda x: x + \".docx\" if not x.endswith(\".docx\") else x)\n",
    "\n",
    "# Trier : d‚Äôabord par base_name, puis par Score d√©croissant\n",
    "df_sorted = df_scores.sort_values([\"base_name\", \"Score\"], ascending=[True, False]).reset_index(drop=True)\n",
    "\n",
    "# On cr√©e un dictionnaire base_name -> score original\n",
    "original_score_dict = df_scores.set_index(\"Fichier\").loc[original_files, \"Score\"].to_dict()\n",
    "\n",
    "# Ajouter la colonne original_score √† tous les fichiers selon leur base_name\n",
    "df_sorted[\"original_score\"] = df_sorted[\"base_name\"].map(original_score_dict)\n",
    "\n",
    "# Calculer le gain par rapport √† l‚Äôoriginal\n",
    "df_sorted[\"gain_vs_original\"] = df_sorted[\"Score\"] - df_sorted[\"original_score\"]\n",
    "\n",
    "# Cr√©er une colonne bool√©enne : True si c'est le CV original\n",
    "df_sorted[\"is_original\"] = df_sorted[\"Fichier\"].isin(original_files)\n",
    "\n",
    "# Trier : d'abord par base_name, puis par is_original (True en premier), puis par Score d√©croissant\n",
    "df_sorted = df_sorted.sort_values(\n",
    "    by=[\"base_name\", \"is_original\", \"Score\"],\n",
    "    ascending=[True, False, False]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Supprimer la colonne temporaire si n√©cessaire\n",
    "df_sorted = df_sorted.drop(columns=\"is_original\")\n",
    "\n",
    "# Affichage lisible\n",
    "for base, group in df_sorted.groupby(\"base_name\"):\n",
    "    print(f\"\\nüìÑ {base}\")\n",
    "    for _, r in group.iterrows():\n",
    "        gain = f\"(+{r['gain_vs_original']:.2f})\" if r['gain_vs_original'] > 0 else f\"({r['gain_vs_original']:.2f})\"\n",
    "        print(f\"   {r['Fichier']:<80} {r['Score']:6.2f} {gain}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d634221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fichier</th>\n",
       "      <th>Score</th>\n",
       "      <th>base_name</th>\n",
       "      <th>original_score</th>\n",
       "      <th>gain_vs_original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CV - Laurent D._14_01_2024.docx</td>\n",
       "      <td>42.045455</td>\n",
       "      <td>CV - Laurent D._14_01_2024.docx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CV_AnaA_20250226.docx</td>\n",
       "      <td>31.818182</td>\n",
       "      <td>CV_AnaA_20250226.docx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CV_CSA_NRJBI_20251016.docx</td>\n",
       "      <td>28.409091</td>\n",
       "      <td>CV_CSA_NRJBI_20251016.docx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRJBI_CEC_CV_Senior_data_engineer_gemini-2.5-pro_enhanced.docx</td>\n",
       "      <td>39.772727</td>\n",
       "      <td>NRJBI_CEC_CV_Senior</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRJBI_CEC_CV_Senior_data_engineer_gemini-2.5-flash_enhanced.docx</td>\n",
       "      <td>29.545455</td>\n",
       "      <td>NRJBI_CEC_CV_Senior</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NRJBI_CEC_CV_Senior_data_engineer_gemini-2.5-flash-lite_enhanced.docx</td>\n",
       "      <td>20.454545</td>\n",
       "      <td>NRJBI_CEC_CV_Senior</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NRJBI_CEC_CV_Senior.docx</td>\n",
       "      <td>17.045455</td>\n",
       "      <td>NRJBI_CEC_CV_Senior</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NRJBI_CEC_CV_Senior_data_engineer_gemini-2.0-flash_enhanced.docx</td>\n",
       "      <td>9.090909</td>\n",
       "      <td>NRJBI_CEC_CV_Senior</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NRJBI_CV_EMO_202510_revisionElise.docx</td>\n",
       "      <td>23.863636</td>\n",
       "      <td>NRJBI_CV_EMO_202510_revisionElise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-pro_enhanced.docx</td>\n",
       "      <td>38.636364</td>\n",
       "      <td>NRJBI_ERE_CV - 20250930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-flash_enhanced.docx</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>NRJBI_ERE_CV - 20250930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-flash_enhanced_surligne.docx</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>NRJBI_ERE_CV - 20250930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NRJBI_ERE_CV - 20250930.docx</td>\n",
       "      <td>35.227273</td>\n",
       "      <td>NRJBI_ERE_CV - 20250930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-flash-lite_enhanced.docx</td>\n",
       "      <td>34.090909</td>\n",
       "      <td>NRJBI_ERE_CV - 20250930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>test.docx</td>\n",
       "      <td>46.590909</td>\n",
       "      <td>test.docx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          Fichier  \\\n",
       "0                                                 CV - Laurent D._14_01_2024.docx   \n",
       "1                                                           CV_AnaA_20250226.docx   \n",
       "2                                                      CV_CSA_NRJBI_20251016.docx   \n",
       "3                  NRJBI_CEC_CV_Senior_data_engineer_gemini-2.5-pro_enhanced.docx   \n",
       "4                NRJBI_CEC_CV_Senior_data_engineer_gemini-2.5-flash_enhanced.docx   \n",
       "5           NRJBI_CEC_CV_Senior_data_engineer_gemini-2.5-flash-lite_enhanced.docx   \n",
       "6                                                        NRJBI_CEC_CV_Senior.docx   \n",
       "7                NRJBI_CEC_CV_Senior_data_engineer_gemini-2.0-flash_enhanced.docx   \n",
       "8                                          NRJBI_CV_EMO_202510_revisionElise.docx   \n",
       "9              NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-pro_enhanced.docx   \n",
       "10           NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-flash_enhanced.docx   \n",
       "11  NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-flash_enhanced_surligne.docx   \n",
       "12                                                   NRJBI_ERE_CV - 20250930.docx   \n",
       "13      NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-flash-lite_enhanced.docx   \n",
       "14                                                                      test.docx   \n",
       "\n",
       "        Score                          base_name  original_score  \\\n",
       "0   42.045455    CV - Laurent D._14_01_2024.docx             NaN   \n",
       "1   31.818182              CV_AnaA_20250226.docx             NaN   \n",
       "2   28.409091         CV_CSA_NRJBI_20251016.docx             NaN   \n",
       "3   39.772727                NRJBI_CEC_CV_Senior             NaN   \n",
       "4   29.545455                NRJBI_CEC_CV_Senior             NaN   \n",
       "5   20.454545                NRJBI_CEC_CV_Senior             NaN   \n",
       "6   17.045455                NRJBI_CEC_CV_Senior             NaN   \n",
       "7    9.090909                NRJBI_CEC_CV_Senior             NaN   \n",
       "8   23.863636  NRJBI_CV_EMO_202510_revisionElise             NaN   \n",
       "9   38.636364            NRJBI_ERE_CV - 20250930             NaN   \n",
       "10  37.500000            NRJBI_ERE_CV - 20250930             NaN   \n",
       "11  37.500000            NRJBI_ERE_CV - 20250930             NaN   \n",
       "12  35.227273            NRJBI_ERE_CV - 20250930             NaN   \n",
       "13  34.090909            NRJBI_ERE_CV - 20250930             NaN   \n",
       "14  46.590909                          test.docx             NaN   \n",
       "\n",
       "    gain_vs_original  \n",
       "0                NaN  \n",
       "1                NaN  \n",
       "2                NaN  \n",
       "3                NaN  \n",
       "4                NaN  \n",
       "5                NaN  \n",
       "6                NaN  \n",
       "7                NaN  \n",
       "8                NaN  \n",
       "9                NaN  \n",
       "10               NaN  \n",
       "11               NaN  \n",
       "12               NaN  \n",
       "13               NaN  \n",
       "14               NaN  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6945f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fichier</th>\n",
       "      <th>Score</th>\n",
       "      <th>base_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CV - Laurent D._14_01_2024.docx</td>\n",
       "      <td>42.045455</td>\n",
       "      <td>CV - Laurent D._14_01_2024.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CV_AnaA_20250226.docx</td>\n",
       "      <td>31.818182</td>\n",
       "      <td>CV_AnaA_20250226.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CV_CSA_NRJBI_20251016.docx</td>\n",
       "      <td>28.409091</td>\n",
       "      <td>CV_CSA_NRJBI_20251016.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NRJBI_CEC_CV_Senior.docx</td>\n",
       "      <td>17.045455</td>\n",
       "      <td>NRJBI_CEC_CV_Senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NRJBI_CEC_CV_Senior_data_engineer_gemini-2.0-flash_enhanced.docx</td>\n",
       "      <td>9.090909</td>\n",
       "      <td>NRJBI_CEC_CV_Senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NRJBI_CEC_CV_Senior_data_engineer_gemini-2.5-flash-lite_enhanced.docx</td>\n",
       "      <td>20.454545</td>\n",
       "      <td>NRJBI_CEC_CV_Senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NRJBI_CEC_CV_Senior_data_engineer_gemini-2.5-flash_enhanced.docx</td>\n",
       "      <td>29.545455</td>\n",
       "      <td>NRJBI_CEC_CV_Senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NRJBI_CEC_CV_Senior_data_engineer_gemini-2.5-pro_enhanced.docx</td>\n",
       "      <td>39.772727</td>\n",
       "      <td>NRJBI_CEC_CV_Senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NRJBI_CV_EMO_202510_revisionElise.docx</td>\n",
       "      <td>23.863636</td>\n",
       "      <td>NRJBI_CV_EMO_202510_revisionElise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NRJBI_ERE_CV - 20250930.docx</td>\n",
       "      <td>35.227273</td>\n",
       "      <td>NRJBI_ERE_CV - 20250930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-flash-lite_enhanced.docx</td>\n",
       "      <td>34.090909</td>\n",
       "      <td>NRJBI_ERE_CV - 20250930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-flash_enhanced.docx</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>NRJBI_ERE_CV - 20250930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-flash_enhanced_surligne.docx</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>NRJBI_ERE_CV - 20250930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-pro_enhanced.docx</td>\n",
       "      <td>38.636364</td>\n",
       "      <td>NRJBI_ERE_CV - 20250930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>test.docx</td>\n",
       "      <td>46.590909</td>\n",
       "      <td>test.docx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          Fichier  \\\n",
       "0                                                 CV - Laurent D._14_01_2024.docx   \n",
       "1                                                           CV_AnaA_20250226.docx   \n",
       "2                                                      CV_CSA_NRJBI_20251016.docx   \n",
       "3                                                        NRJBI_CEC_CV_Senior.docx   \n",
       "4                NRJBI_CEC_CV_Senior_data_engineer_gemini-2.0-flash_enhanced.docx   \n",
       "5           NRJBI_CEC_CV_Senior_data_engineer_gemini-2.5-flash-lite_enhanced.docx   \n",
       "6                NRJBI_CEC_CV_Senior_data_engineer_gemini-2.5-flash_enhanced.docx   \n",
       "7                  NRJBI_CEC_CV_Senior_data_engineer_gemini-2.5-pro_enhanced.docx   \n",
       "8                                          NRJBI_CV_EMO_202510_revisionElise.docx   \n",
       "9                                                    NRJBI_ERE_CV - 20250930.docx   \n",
       "10      NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-flash-lite_enhanced.docx   \n",
       "11           NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-flash_enhanced.docx   \n",
       "12  NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-flash_enhanced_surligne.docx   \n",
       "13             NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-pro_enhanced.docx   \n",
       "14                                                                      test.docx   \n",
       "\n",
       "        Score                          base_name  \n",
       "0   42.045455    CV - Laurent D._14_01_2024.docx  \n",
       "1   31.818182              CV_AnaA_20250226.docx  \n",
       "2   28.409091         CV_CSA_NRJBI_20251016.docx  \n",
       "3   17.045455                NRJBI_CEC_CV_Senior  \n",
       "4    9.090909                NRJBI_CEC_CV_Senior  \n",
       "5   20.454545                NRJBI_CEC_CV_Senior  \n",
       "6   29.545455                NRJBI_CEC_CV_Senior  \n",
       "7   39.772727                NRJBI_CEC_CV_Senior  \n",
       "8   23.863636  NRJBI_CV_EMO_202510_revisionElise  \n",
       "9   35.227273            NRJBI_ERE_CV - 20250930  \n",
       "10  34.090909            NRJBI_ERE_CV - 20250930  \n",
       "11  37.500000            NRJBI_ERE_CV - 20250930  \n",
       "12  37.500000            NRJBI_ERE_CV - 20250930  \n",
       "13  38.636364            NRJBI_ERE_CV - 20250930  \n",
       "14  46.590909                          test.docx  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44384e86",
   "metadata": {},
   "source": [
    "#### Crit√®res = pr√©sence ou absence + fr√©quence de mot-cl√©s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa12c6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score de correspondance pour CV - Laurent D._14_01_2024.docx : 29.5 %\n",
      "Score de correspondance pour CV_AnaA_20250226.docx : 22.3 %\n",
      "Score de correspondance pour CV_CSA_NRJBI_20251016.docx : 16.7 %\n",
      "Score de correspondance pour NRJBI_CEC_CV_Senior.docx : 12.1 %\n",
      "Score de correspondance pour NRJBI_CEC_CV_Senior_data_engineer_gemini-2.0-flash_enhanced.docx : 3.8 %\n",
      "Score de correspondance pour NRJBI_CEC_CV_Senior_data_engineer_gemini-2.5-flash-lite_enhanced.docx : 14.8 %\n",
      "Score de correspondance pour NRJBI_CEC_CV_Senior_data_engineer_gemini-2.5-flash_enhanced.docx : 20.1 %\n",
      "Score de correspondance pour NRJBI_CEC_CV_Senior_data_engineer_gemini-2.5-pro_enhanced.docx : 25.0 %\n",
      "Score de correspondance pour NRJBI_CV_EMO_202510_revisionElise.docx : 17.0 %\n",
      "Score de correspondance pour NRJBI_ERE_CV - 20250930.docx : 22.3 %\n",
      "Score de correspondance pour NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-flash-lite_enhanced.docx : 19.7 %\n",
      "Score de correspondance pour NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-flash_enhanced.docx : 25.8 %\n",
      "Score de correspondance pour NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-flash_enhanced_surligne.docx : 25.8 %\n",
      "Score de correspondance pour NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-pro_enhanced.docx : 29.2 %\n",
      "Score de correspondance pour test.docx : 29.5 %\n"
     ]
    }
   ],
   "source": [
    "# Test sur plusieurs CV \n",
    "# Faire une boucle sur les CV dans le dossier CVs\n",
    "dossier_cvs = \"CVs\"\n",
    "all_scores = {}\n",
    "for nom_fichier in os.listdir(dossier_cvs):\n",
    "    # Lis un CV .docx\n",
    "    cv_text = lire_docx(f\"./{dossier_cvs}/{nom_fichier}\")\n",
    "    Score = score_cv_frequence(cv_text, offre, max_occurrences=3)\n",
    "    all_scores[nom_fichier] = Score\n",
    "    print(f\"Score de correspondance pour {nom_fichier} : {Score:.1f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a046d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ CV - Laurent D._14_01_2024.docx\n",
      "   CV - Laurent D._14_01_2024.docx                                                   42.05 (nan)\n",
      "\n",
      "üìÑ CV_AnaA_20250226.docx\n",
      "   CV_AnaA_20250226.docx                                                             31.82 (nan)\n",
      "\n",
      "üìÑ CV_CSA_NRJBI_20251016.docx\n",
      "   CV_CSA_NRJBI_20251016.docx                                                        28.41 (nan)\n",
      "\n",
      "üìÑ NRJBI_CEC_CV_Senior.docx\n",
      "   NRJBI_CEC_CV_Senior.docx                                                          17.05 (0.00)\n",
      "   NRJBI_CEC_CV_Senior_data_engineer_gemini-2.5-pro_enhanced.docx                    39.77 (+22.73)\n",
      "   NRJBI_CEC_CV_Senior_data_engineer_gemini-2.5-flash_enhanced.docx                  29.55 (+12.50)\n",
      "   NRJBI_CEC_CV_Senior_data_engineer_gemini-2.5-flash-lite_enhanced.docx             20.45 (+3.41)\n",
      "   NRJBI_CEC_CV_Senior_data_engineer_gemini-2.0-flash_enhanced.docx                   9.09 (-7.95)\n",
      "\n",
      "üìÑ NRJBI_CV_EMO_202510_revisionElise.docx\n",
      "   NRJBI_CV_EMO_202510_revisionElise.docx                                            23.86 (0.00)\n",
      "\n",
      "üìÑ NRJBI_ERE_CV - 20250930.docx\n",
      "   NRJBI_ERE_CV - 20250930.docx                                                      35.23 (0.00)\n",
      "   NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-pro_enhanced.docx                38.64 (+3.41)\n",
      "   NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-flash_enhanced.docx              37.50 (+2.27)\n",
      "   NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-flash_enhanced_surligne.docx     37.50 (+2.27)\n",
      "   NRJBI_ERE_CV - 20250930_data_engineer_gemini-2.5-flash-lite_enhanced.docx         34.09 (-1.14)\n",
      "\n",
      "üìÑ test.docx\n",
      "   test.docx                                                                         46.59 (nan)\n"
     ]
    }
   ],
   "source": [
    "# Affichage par ordre croissant pour chaque groupe de CVs communs (CV original + CV am√©lior√©s)\n",
    "# Liste connue des fichiers originaux\n",
    "original_files = [\n",
    "    \"NRJBI_CEC_CV_Senior.docx\",\n",
    "    \"NRJBI_ERE_CV - 20250930.docx\",\n",
    "    \"NRJBI_CV_EMO_202510_revisionElise.docx\",\n",
    "]\n",
    "\n",
    "# Extraire juste le nom sans extension pour faciliter la recherche\n",
    "original_bases = [f.rsplit('.', 1)[0] for f in original_files]\n",
    "\n",
    "# Trouver √† quel original correspond chaque fichier\n",
    "def find_base(Fichier):\n",
    "    for base in original_bases:\n",
    "        if Fichier.startswith(base):  # on compare le d√©but du nom\n",
    "            return base\n",
    "    return Fichier  # si aucun match, on garde le nom lui-m√™me\n",
    "\n",
    "df_scores[\"base_name\"] = df_scores[\"Fichier\"].apply(find_base)\n",
    "\n",
    "# S'il manque l'extension .docx dans base_name, on l'ajoute pour correspondre aux cl√©s originales\n",
    "df_scores[\"base_name\"] = df_scores[\"base_name\"].apply(lambda x: x + \".docx\" if not x.endswith(\".docx\") else x)\n",
    "\n",
    "# Trier : d‚Äôabord par base_name, puis par Score d√©croissant\n",
    "df_sorted = df_scores.sort_values([\"base_name\", \"Score\"], ascending=[True, False]).reset_index(drop=True)\n",
    "\n",
    "# On cr√©e un dictionnaire base_name -> score original\n",
    "original_score_dict = df_scores.set_index(\"Fichier\").loc[original_files, \"Score\"].to_dict()\n",
    "\n",
    "# Ajouter la colonne original_score √† tous les fichiers selon leur base_name\n",
    "df_sorted[\"original_score\"] = df_sorted[\"base_name\"].map(original_score_dict)\n",
    "\n",
    "# Calculer le gain par rapport √† l‚Äôoriginal\n",
    "df_sorted[\"gain_vs_original\"] = df_sorted[\"Score\"] - df_sorted[\"original_score\"]\n",
    "\n",
    "# Cr√©er une colonne bool√©enne : True si c'est le CV original\n",
    "df_sorted[\"is_original\"] = df_sorted[\"Fichier\"].isin(original_files)\n",
    "\n",
    "# Trier : d'abord par base_name, puis par is_original (True en premier), puis par Score d√©croissant\n",
    "df_sorted = df_sorted.sort_values(\n",
    "    by=[\"base_name\", \"is_original\", \"Score\"],\n",
    "    ascending=[True, False, False]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Supprimer la colonne temporaire si n√©cessaire\n",
    "df_sorted = df_sorted.drop(columns=\"is_original\")\n",
    "\n",
    "# Affichage lisible\n",
    "for base, group in df_sorted.groupby(\"base_name\"):\n",
    "    print(f\"\\nüìÑ {base}\")\n",
    "    for _, r in group.iterrows():\n",
    "        gain = f\"(+{r['gain_vs_original']:.2f})\" if r['gain_vs_original'] > 0 else f\"({r['gain_vs_original']:.2f})\"\n",
    "        print(f\"   {r['Fichier']:<80} {r['Score']:6.2f} {gain}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9844dede",
   "metadata": {},
   "source": [
    "### Version tout le CV offre transform√©s en vecteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8eae0f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\eupho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# --- REQUIREMENTS ---\n",
    "# pip install scikit-learn nltk\n",
    "# ---------------------------------------------\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk, os, re\n",
    "from docx import Document\n",
    "\n",
    "# T√©l√©chargement du stopword fran√ßais\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_fr = stopwords.words('french')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166c5d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fonctions ---\n",
    "\n",
    "def lire_docx(path):\n",
    "    \"\"\"Extrait le texte brut d'un fichier Word (.docx).\"\"\"\n",
    "    doc = Document(path)\n",
    "    full_text = [p.text for p in doc.paragraphs]\n",
    "    return \"\\n\".join(full_text)\n",
    "\n",
    "def nettoyer_texte(texte: str) -> str:\n",
    "    \"\"\"Nettoie et normalise un texte fran√ßais.\"\"\"\n",
    "    texte = texte.lower()\n",
    "    texte = re.sub(r\"[^a-z√†√¢√ß√©√®√™√´√Æ√Ø√¥√ª√π√º√ø√±√¶≈ì0-9\\s]\", \" \", texte)\n",
    "    texte = re.sub(r\"\\s+\", \" \", texte)\n",
    "    texte = re.sub(r\"\\d+\", \" \", texte)  # supprime tous les nombres\n",
    "    return texte.strip()\n",
    "\n",
    "def score_cv_contre_offre(cv_text, offre_text):\n",
    "    \"\"\"Calcule le Score TF-IDF entre un CV unique et l'offre.\"\"\"\n",
    "    # Nettoyage des textes\n",
    "    cv_clean = nettoyer_texte(cv_text)\n",
    "    offre_clean = nettoyer_texte(offre_text)\n",
    "\n",
    "    # TF-IDF\n",
    "    vectorizer = CountVectorizer(stop_words=stop_fr, ngram_range=(1,1))\n",
    "    count_words = vectorizer.fit_transform([offre_clean, cv_clean])\n",
    "\n",
    "    # Vecteurs\n",
    "    offre_vec = count_words[0:1]\n",
    "    cv_vec = count_words[1:2]\n",
    "\n",
    "    # Similarit√© cosinus\n",
    "    Score = cosine_similarity(offre_vec, cv_vec)[0][0]\n",
    "    return Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d46e008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score de correspondance : 38.9 %\n"
     ]
    }
   ],
   "source": [
    "# Lis l'offre\n",
    "offre_text = \"\"\"Dans le cadre de sa mission d‚Äôexploitation et de valorisation des donn√©es m√©dicales, \n",
    "la DIDM fait face √† un besoin croissant de donn√©es fiables. Vous viendrez compl√©ter une √©quipe...\n",
    "Excellente ma√Ætrise de SQL (Oracle) et solide exp√©rience en R...\n",
    "Pratique des outils de versioning (Git, Bitbucket, Github)\n",
    "Exp√©rience avec un outil ETL, id√©alement Talend\n",
    "Une premi√®re approche de la dataviz (Tableau, QlikView) est un atout.\"\"\"\n",
    "\n",
    "# Lis un CV .docx\n",
    "cv_text = lire_docx(\"test.docx\")\n",
    "\n",
    "# Calcul du Score\n",
    "Score = score_cv_contre_offre(cv_text, offre_text)\n",
    "print(f\"Score de correspondance : {Score*100:.1f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "41b39b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ing√©nieur Data / D√©veloppeur BI ‚Äì Sp√©cialisation donn√©es m√©dicales\\nEmail : jean.dupont@example.com\\nT√©l√©phone : 06 45 89 22 77\\n\\nProfil\\nData engineer exp√©riment√© dans l‚Äôexploitation, la fiabilit√© et la valorisation de donn√©es m√©dicales.\\nHabitu√© √† mod√©liser des flux de donn√©es, construire des pipelines ETL complexes sous Talend et SQL (Oracle), et √† assurer la qualit√©, la s√©curit√© et la tra√ßabilit√© des donn√©es pour des environnements analytiques et d√©cisionnels (BI, tableaux de bord, reporting).\\n\\nComp√©tences cl√©s\\nLangages : SQL (Oracle, PostgreSQL), R, Java, Scala, Julia (bases)\\nOutils ETL / Data Pipeline : Talend, Airflow, DataStage\\nBusiness Intelligence : Tableau, QlikView, Power BI\\nVersioning : Git, Bitbucket, GitHub\\nData Modeling : conception de sch√©mas, mod√©lisation de tables, int√©gration de donn√©es h√©t√©rog√®nes\\nQualit√© & S√©curit√© : validation des datasets, contr√¥les de coh√©rence, gestion des acc√®s et anonymisation\\nBonnes pratiques : documentation, revue de code, standards de d√©veloppement BI\\nAutres outils : Linux, Bash, Excel avanc√©, Jupyter, RStudio\\n\\nExp√©rience professionnelle\\n2021 ‚Äì aujourd‚Äôhui : Data Engineer ‚Äì D√©partement d‚ÄôInformation et Donn√©es M√©dicales (DIDM), H√¥pital Saint-Louis ‚Äì Paris\\nConstruction de pipelines de donn√©es pour alimenter la BI et l‚Äôanalytique.\\nMod√©lisation et structuration de flux, tables et sch√©mas de donn√©es m√©dicales.\\nD√©veloppement de datasets BI utilis√©s pour les tableaux de bord Tableau et QlikView.\\nMise en place de standards de d√©veloppement et de bonnes pratiques (Git + Talend).\\nSupport et r√©solution d‚Äôincidents sur le p√©rim√®tre data.\\nGarantir la fiabilit√© et la s√©curit√© des donn√©es selon les contraintes CNIL et RGPD.\\n2018 ‚Äì 2021 : Analyste D√©veloppeur BI ‚Äì Laboratoires Sant√© France\\nD√©veloppement d‚ÄôETL sous Talend et int√©gration Oracle.\\nMod√©lisation de l‚Äôentrep√¥t de donn√©es (sch√©ma en √©toile).\\nTableaux de bord interactifs sous Tableau et QlikView.\\nNettoyage, validation et contr√¥le qualit√© des datasets.\\n\\nFormation\\nMaster Informatique ‚Äì Sp√©cialisation Data Engineering et BI (Universit√© de Lyon)\\nCertification Talend Data Integration Advanced\\nCertification Oracle SQL Expert\\nCertification GitHub Foundations\\n\\nLangues\\nFran√ßais (natif)\\nAnglais (professionnel)\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c064943b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07637796, 0.27880457])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9cd75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.3672651915581337\n"
     ]
    }
   ],
   "source": [
    "#Scoring CV hors fonction\n",
    "\"\"\"Calcule le Score TF-IDF entre un CV unique et l'offre.\"\"\"\n",
    "# Nettoyage des textes\n",
    "cv_clean = nettoyer_texte(cv_text)\n",
    "offre_clean = nettoyer_texte(offre_text)\n",
    "\n",
    "# TF-IDF\n",
    "vectorizer = CountVectorizer(stop_words=stop_fr, ngram_range=(1,1))\n",
    "count_words = vectorizer.fit_transform([offre_clean, cv_clean])\n",
    "\n",
    "# Vecteurs\n",
    "offre_vec = count_words[0:1]\n",
    "cv_vec = count_words[1:2]\n",
    "\n",
    "# Similarit√© cosinus\n",
    "Score = cosine_similarity(offre_vec, cv_vec)[0][0]\n",
    "print(\"Score:\", Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f9abc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc√®s' 'advanced' 'airflow' 'alimenter' 'analyste' 'analytique'\n",
      " 'analytiques' 'anglais' 'anonymisation' 'approche' 'assurer' 'atout'\n",
      " 'aujourd' 'autres' 'avanc√©' 'bases' 'bash' 'besoin' 'bi' 'bitbucket'\n",
      " 'bonnes' 'bord' 'business' 'cadre' 'certification' 'cl√©s' 'cnil' 'code'\n",
      " 'coh√©rence' 'com' 'complexes' 'compl√©ter' 'comp√©tences' 'conception'\n",
      " 'construction' 'construire' 'contraintes' 'contr√¥le' 'contr√¥les'\n",
      " 'croissant' 'data' 'datasets' 'datastage' 'dataviz' 'didm'\n",
      " 'documentation' 'donn√©es' 'dupont' 'd√©cisionnels' 'd√©partement'\n",
      " 'd√©veloppement' 'd√©veloppeur' 'email' 'engineer' 'engineering' 'entrep√¥t'\n",
      " 'environnements' 'etl' 'example' 'excel' 'excellente' 'expert'\n",
      " 'exploitation' 'exp√©rience' 'exp√©riment√©' 'face' 'fait' 'fiabilit√©'\n",
      " 'fiables' 'flux' 'formation' 'foundations' 'france' 'fran√ßais' 'garantir'\n",
      " 'gestion' 'git' 'github' 'habitu√©' 'hui' 'h√©t√©rog√®nes' 'h√¥pital'\n",
      " 'id√©alement' 'incidents' 'information' 'informatique' 'ing√©nieur'\n",
      " 'integration' 'intelligence' 'interactifs' 'int√©gration' 'java' 'jean'\n",
      " 'julia' 'jupyter' 'laboratoires' 'langages' 'langues' 'linux' 'louis'\n",
      " 'lyon' 'master' 'ma√Ætrise' 'mise' 'mission' 'modeling' 'mod√©lisation'\n",
      " 'mod√©liser' 'm√©dicales' 'natif' 'nettoyage' 'oracle' 'outil' 'outils'\n",
      " 'paris' 'pipeline' 'pipelines' 'place' 'postgresql' 'power' 'pratique'\n",
      " 'pratiques' 'premi√®re' 'professionnel' 'professionnelle' 'profil'\n",
      " 'p√©rim√®tre' 'qlikview' 'qualit√©' 'reporting' 'revue' 'rgpd' 'rstudio'\n",
      " 'r√©solution' 'saint' 'sant√©' 'scala' 'sch√©ma' 'sch√©mas' 'selon' 'solide'\n",
      " 'sous' 'sp√©cialisation' 'sql' 'standards' 'structuration' 'support'\n",
      " 's√©curit√©' 'tableau' 'tableaux' 'tables' 'talend' 'tra√ßabilit√©'\n",
      " 't√©l√©phone' 'universit√©' 'utilis√©s' 'validation' 'valorisation'\n",
      " 'versioning' 'viendrez' '√©quipe' '√©toile']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "934835c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dans le cadre de sa mission d exploitation et de valorisation des donn√©es m√©dicales la didm fait face √† un besoin croissant de donn√©es fiables vous viendrez compl√©ter une √©quipe excellente ma√Ætrise de sql oracle et solide exp√©rience en r pratique des outils de versioning git bitbucket github exp√©rience avec un outil etl id√©alement talend une premi√®re approche de la dataviz tableau qlikview est un atout\n"
     ]
    }
   ],
   "source": [
    "print(offre_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff91f504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x1164 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 181 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offre_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6076a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x1164 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1285 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e792ce45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dans le cadre de sa mission d exploitation et de valorisation des donn√©es m√©dicales la didm fait face √† un besoin croissant de donn√©es fiables c est pourquoi un nouveau poste est cr√©√© vous viendrez compl√©ter une √©quipe compos√©e d une charg√©e d √©tudes et d√©veloppements √† 50 et d un responsable etudes et d√©veloppements sous la responsabilit√© de ce dernier vos missions seront les suivantes construire des pipelines de donn√©es pour alimenter la bi et l analytique mod√©liser et structurer les flux tables et sch√©mas garantir la qualit√© la fiabilit√© et la s√©curit√© des donn√©es d√©velopper de nouveaux datasets pour la bi de la didm mettre en place des standards de d√©veloppement et de bonnes pratiques assurer le support et la r√©solution des incidents sur votre p√©rim√®tre votre bo√Æte √† outils excellente ma√Ætrise de sql oracle et solide exp√©rience en r connaissances en julia java ou scala appr√©ci√©es pratique des outils de versioning git bitbucket github exp√©rience avec un outil etl id√©alement talend une premi√®re approche de la dataviz tableau qlikview est un atout',\n",
       " 'christopher eck senior ing√©nieur data nous contacter 06 14 15 10 85 jba nrjbi com pr√©sentation profil polyvalent technique fonctionnel avec une expertise sur l environnement data microsoft sql server ssis ssas synapse azure cloud power bi gestion d √©quipe technique 5 autres d√©veloppeurs et r√©f√©rent technique pendant plus de 2 ans chez saint gobain comp√©tences exp√©riences cl√©s formations certification power bi pl 300 ielts 8 0 formation data analyst ing√©nieur bi nrjbi oct 2019 d√©c 2019 dipl√¥me ing√©nieur ece paris 2014 2017 d√©tail des missions responsable data pour la migration de l ensemble de l architecture data du m√©tier mobility sql server ssis server agent jobs vers la plateforme azure synapse avec optimisation de proc√©dure stock√©e gestion des mep azure devops r√©f√©rent technique d une √©quipe de 5 d√©veloppeurs √©valuation technique analyse des packages et proc√©dure stock√©es existantes onprem pour les traduire et optimiser dans une version synapse traduction de code abac sap en proc√©dure stock√©e pour int√©gration de donn√©es sap dans azure sql d√©veloppeur data cr√©ation sur synapse de linked services datasets pipelines tables vues proc√©dure stock√©es triggers pour int√©grer sql server postgresql api fichier csv fichier parquet transformer et faire des calculs sur les donn√©es pour alimenter un datawarehouse propre et optimis√© architecture data conception du process de concat√©nation entre les donn√©es historiques de sap les nouvelles donn√©es de tesseract et les donn√©es historiques de onprem avec mis en place de merge et de mapping variabilis√©s dans une nouvelle table responsable des mep mise en place de process et planning de mep avant l int√©gration d azure devops et de ci cd puis mise en place de process d √©quipe et de validation de recette avec azure devops responsable de la documentation technique traduction et conception de tous les documents techniques pour le projet de migration dans confluence r√©f√©rent technique pour 5 ing√©nieur data organisation d oto hebdomadaire aide technique pour d√©bloquer des probl√®mes d optimisation ou de traduction revue de code avant mep responsable du run onprem et synapse r√©solution d incidents sur la partie onprem et synapse r√©alisation d un audit de la performance de la plateforme synapse d un autre projet suite √† l audit mise en place d un projet d optimisation avec estimation de la dur√©e du projet et de ses impacts sur la performance conception d un process avec un notebook pyspark pour lire des fichiers delta dans un deltalake azure et faire un load incr√©mentale dans une base externe sql serveur environnement sql server ssis synapse azure datawarehouse azure devops confluence jira business analyst et d√©veloppeur bi pour l ensemble des m√©tiers toyota du recueil des besoins m√©tiers √† l int√©gration des donn√©es jusqu √† la cr√©ation de rapport power bi responsable projet data recueil des besoins des probl√©matiques m√©tiers et d√©finition des sp√©cifications fonctionnelles demand√© par le m√©tier analyse de la donn√©e m√©tier pour l int√©grer au data model existant estimation de la dur√©e du projet d√©veloppeur bi int√©gration des donn√©es dans la base de donn√©es sql server dans le format stg ods dwh avec des packages ssis pour la transformation des donn√©es entre les diff√©rents storage int√©gration des nouvelles donn√©es dans le data mod√®le avec les jointures n√©cessaires cr√©ation de kpi dans un cube ssas √† l aide de formule dax d√©veloppeur power bi cr√©ation de rapport power bi ainsi que de template toyota pour l ensemble des rapports power bi de la soci√©t√© formateur formation d utilisateurs m√©tiers √† l utilisation de power bi environ 30 collaborateurs et des templates de la soci√©t√© responsable du run r√©solution d incidents sql ssis ssas et power bi pour l ensemble de l architecture data de toyota responsable du projet de nomenclature toyota d√©finition de toutes les r√®gles de nomenclatures pour les objets sql power bi et les formules dax pour uniformiser la vision totoya application de mise en place de la nouvelle nomenclature sur plus de 2000 kpi 1000 tables 200 packages environnement sql server ssis ssas power bi servicenow d√©veloppeur microstrategy pour la recette de la migration des rapports qlikview vers microstrategy recette des donn√©es et des kpi d une trentaine de rapports migr√©s de qlikview vers microstrategy pour le chef de projet cr√©ation et optimisation de visuels sur microstrategy pour correspondre aux visuels qlikview environnement microstrategy tableau snowflake sql responsable de l automatisation du suivi et de l analyse des tableaux de bords sociaux de l entreprise pour la direction et les drh du groupe lagard√®re active automatisation avec excel vba de la cr√©ation et des calculs des rapports sociaux de l entreprise rse bilan social effectif masse salariale mobilit√©s cr√©ation et mise en place de maquette de calcul automatis√©es excel avec leur proc√©dure d utilisation et la formation d utilisateurs pour fiabiliser le contr√¥le des donn√©es de la paie dns net √† payer calcul part variable responsable du run pour l extraction la transformation et l analyse de donn√©es pour r√©pondre aux besoins des diff√©rentes directions du groupe avec peoplesoft et excel g√©n√©rale rh finance contr√¥le de gestion environnement peoplesoft excel vba',\n",
       " 'ing√©nieur data d√©veloppeur bi sp√©cialisation donn√©es m√©dicales email jean dupont example com t√©l√©phone 06 45 89 22 77 profil data engineer exp√©riment√© dans l exploitation la fiabilit√© et la valorisation de donn√©es m√©dicales habitu√© √† mod√©liser des flux de donn√©es construire des pipelines etl complexes sous talend et sql oracle et √† assurer la qualit√© la s√©curit√© et la tra√ßabilit√© des donn√©es pour des environnements analytiques et d√©cisionnels bi tableaux de bord reporting comp√©tences cl√©s langages sql oracle postgresql r java scala julia bases outils etl data pipeline talend airflow datastage business intelligence tableau qlikview power bi versioning git bitbucket github data modeling conception de sch√©mas mod√©lisation de tables int√©gration de donn√©es h√©t√©rog√®nes qualit√© s√©curit√© validation des datasets contr√¥les de coh√©rence gestion des acc√®s et anonymisation bonnes pratiques documentation revue de code standards de d√©veloppement bi autres outils linux bash excel avanc√© jupyter rstudio exp√©rience professionnelle 2021 aujourd hui data engineer d√©partement d information et donn√©es m√©dicales didm h√¥pital saint louis paris construction de pipelines de donn√©es pour alimenter la bi et l analytique mod√©lisation et structuration de flux tables et sch√©mas de donn√©es m√©dicales d√©veloppement de datasets bi utilis√©s pour les tableaux de bord tableau et qlikview mise en place de standards de d√©veloppement et de bonnes pratiques git talend support et r√©solution d incidents sur le p√©rim√®tre data garantir la fiabilit√© et la s√©curit√© des donn√©es selon les contraintes cnil et rgpd 2018 2021 analyste d√©veloppeur bi laboratoires sant√© france d√©veloppement d etl sous talend et int√©gration oracle mod√©lisation de l entrep√¥t de donn√©es sch√©ma en √©toile tableaux de bord interactifs sous tableau et qlikview nettoyage validation et contr√¥le qualit√© des datasets formation master informatique sp√©cialisation data engineering et bi universit√© de lyon certification talend data integration advanced certification oracle sql expert certification github foundations langues fran√ßais natif anglais professionnel']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "331c7633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(cv_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc551d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aceaf001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dans le cadre de sa mission d‚Äôexploitation et de valorisation des donn√©es m√©dicales, la DIDM fait face √† un besoin croissant de donn√©es fiables. C‚Äôest pourquoi un nouveau poste est cr√©√©.\\nVous viendrez compl√©ter une √©quipe compos√©e d‚Äôune Charg√©e d‚Äô√©tudes et d√©veloppements √† 50 % et d‚Äôun Responsable Etudes et D√©veloppements. Sous la responsabilit√© de ce dernier, vos missions seront les suivantes :\\nConstruire des pipelines de donn√©es pour alimenter la BI et l‚Äôanalytique.\\nMod√©liser et structurer les flux, tables et sch√©mas\\nGarantir la qualit√©, la fiabilit√© et la s√©curit√© des donn√©es\\nD√©velopper de nouveaux datasets pour la BI de la DIDM\\nMettre en place des standards de d√©veloppement et de bonnes pratiques\\nAssurer le support et la r√©solution des incidents sur votre p√©rim√®tre...\\n\\nVotre bo√Æte √† outils\\nExcellente ma√Ætrise de SQL (Oracle) et solide exp√©rience en R\\nConnaissances en Julia, Java ou Scala appr√©ci√©es\\nPratique des outils de versioning (Git, Bitbucket, Github)\\nExp√©rience avec un outil ETL, id√©alement Talend\\nUne premi√®re approche de la dataviz (Tableau, QlikView) est un atout',\n",
       " '\\n\\n\\n\\nCHRISTOPHER ECK\\nSenior Ing√©nieur Data\\n\\n\\n\\n\\n\\n\\nNous contacter\\xa0:\\n 06.14.15.10.85\\n  jba@nrjbi.com\\n\\n  \\n\\n\\n\\n\\n\\n\\nPr√©sentation\\n\\nProfil polyvalent technique / fonctionnel, avec une expertise sur l‚Äôenvironnement data Microsoft (SQL Server, SSIS, SSAS, Synapse, Azure Cloud, Power BI). Gestion d‚Äô√©quipe technique (5 autres d√©veloppeurs) et r√©f√©rent technique pendant plus de 2 ans chez Saint-Gobain.\\n\\n\\nComp√©tences\\n\\n\\nExp√©riences - Cl√©s\\n\\n\\nFormations\\n\\nCertification Power BI PL-300\\n\\nIELTS (8.0)\\n\\nFormation Data Analyst / Ing√©nieur BI NRJBI (oct 2019 ‚Äì d√©c 2019)\\n\\nDipl√¥me Ing√©nieur ECE Paris (2014-2017)\\n\\n\\nD√©tail des missions\\n\\n\\nResponsable data pour la Migration de l‚Äôensemble de l‚Äôarchitecture data du m√©tier Mobility (SQL server, SSIS, Server Agent Jobs) vers la plateforme Azure Synapse, avec optimisation de proc√©dure stock√©e, gestion des MEP (Azure Devops), r√©f√©rent technique d‚Äôune √©quipe de 5 d√©veloppeurs.\\n\\n√âvaluation technique : Analyse des packages et proc√©dure stock√©es existantes OnPrem pour les traduire et optimiser dans une version Synapse. Traduction de code ABAC (SAP) en proc√©dure stock√©e pour int√©gration de donn√©es SAP dans Azure SQL.\\n\\nD√©veloppeur Data\\xa0: Cr√©ation sur Synapse de Linked services, Datasets, Pipelines, Tables, Vues, Proc√©dure stock√©es, Triggers pour int√©grer (SQL Server, PostgreSQL, API, Fichier CSV, Fichier Parquet‚Ä¶), transformer et faire des calculs sur les donn√©es pour alimenter un datawarehouse propre et optimis√©.\\n\\nArchitecture Data\\xa0: Conception du process de concat√©nation entre les donn√©es historiques de SAP, les nouvelles donn√©es de Tesseract et les donn√©es historiques de OnPrem avec mis en place de MERGE et de mapping variabilis√©s dans une nouvelle table.\\n\\nResponsable des MEP : Mise en place de process et planning de MEP avant l‚Äôint√©gration d‚ÄôAzure DevOps et de CI/CD. Puis mise en place de process d‚Äô√©quipe et de validation de recette avec Azure DevOps.\\n\\nResponsable de la documentation technique : Traduction et conception de tous les documents techniques pour le projet de migration dans Confluence.\\n\\nR√©f√©rent technique pour 5 Ing√©nieur Data, organisation d‚ÄôOTO hebdomadaire, aide technique pour d√©bloquer des probl√®mes d‚Äôoptimisation ou de traduction, revue de code avant MEP.\\n\\nResponsable du Run OnPrem et Synapse : R√©solution d‚Äôincidents sur la partie OnPrem et Synapse.\\n\\nR√©alisation d‚Äôun audit de la performance de la plateforme Synapse d‚Äôun autre projet. Suite √† l‚Äôaudit, mise en place d‚Äôun projet d‚Äôoptimisation avec estimation de la dur√©e du projet et de ses impacts sur la performance.\\n\\nConception d‚Äôun process avec un notebook Pyspark pour lire des fichiers delta dans un Deltalake Azure, et faire un load incr√©mentale dans une base externe SQL serveur.\\n\\nEnvironnement : SQL Server, SSIS, Synapse, Azure Datawarehouse, Azure DevOps, Confluence, Jira\\n\\n\\nBusiness Analyst et d√©veloppeur BI pour l‚Äôensemble des m√©tiers Toyota du recueil des besoins m√©tiers √† l‚Äôint√©gration des donn√©es jusqu‚Äô√† la cr√©ation de rapport Power BI.\\n\\nResponsable projet Data : Recueil des besoins des probl√©matiques m√©tiers et d√©finition des sp√©cifications fonctionnelles demand√© par le m√©tier. Analyse de la donn√©e m√©tier pour l‚Äôint√©grer au data model existant. Estimation de la dur√©e du projet.\\n\\nD√©veloppeur BI\\xa0: Int√©gration des donn√©es dans la base de donn√©es SQL Server dans le format STG -> ODS -> DWH avec des packages SSIS pour la transformation des donn√©es entre les diff√©rents storage. Int√©gration des nouvelles donn√©es dans le data mod√®le avec les jointures n√©cessaires. Cr√©ation de KPI dans un cube SSAS √† l‚Äôaide de formule DAX.\\n\\nD√©veloppeur Power BI\\xa0: Cr√©ation de rapport Power BI ainsi que de template Toyota pour l‚Äôensemble des rapports Power BI de la soci√©t√©.\\n\\nFormateur\\xa0: Formation d‚Äôutilisateurs m√©tiers √† l‚Äôutilisation de Power BI (environ 30 collaborateurs) et des templates de la soci√©t√©.\\n\\nResponsable du Run : R√©solution d‚Äôincidents SQL, SSIS, SSAS et Power BI pour l‚Äôensemble de l‚Äôarchitecture data de Toyota.\\n\\nResponsable du projet de nomenclature Toyota\\xa0: d√©finition de toutes les r√®gles de nomenclatures pour les objets SQL, Power BI et les formules DAX pour uniformiser la vision Totoya. Application de mise en place de la nouvelle nomenclature sur plus de 2000 KPI, 1000 tables, 200 packages. \\n\\nEnvironnement : SQL Server, SSIS, SSAS, Power BI, ServiceNow\\n\\n\\n\\nD√©veloppeur MicroStrategy pour la recette de la Migration des rapports Qlikview vers MicroStrategy.\\n\\nRecette des donn√©es et des KPI d‚Äôune trentaine de rapports migr√©s de Qlikview vers MicroStrategy pour le chef de projet.\\n\\nCr√©ation et optimisation de visuels sur MicroStrategy pour correspondre aux visuels Qlikview.\\n\\nEnvironnement : MicroStrategy, Tableau, Snowflake, SQL\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nResponsable de l‚Äôautomatisation, du suivi et de l‚Äôanalyse des tableaux de bords sociaux de l‚Äôentreprise pour la Direction et les DRH du groupe Lagard√®re Active.\\n\\nAutomatisation avec Excel VBA de la cr√©ation et des calculs des rapports sociaux de l‚Äôentreprise (RSE, Bilan social, Effectif, Masse Salariale, Mobilit√©s).\\n\\nCr√©ation et mise en place de maquette de calcul automatis√©es Excel avec leur proc√©dure d‚Äôutilisation et la formation d‚Äôutilisateurs pour fiabiliser le contr√¥le des donn√©es de la paie (DNS, Net √† payer, Calcul part variable).\\n\\nResponsable du Run pour l‚Äôextraction, la transformation et l‚Äôanalyse de donn√©es pour r√©pondre aux besoins des diff√©rentes directions du Groupe avec PeopleSoft et Excel (G√©n√©rale, RH, Finance, Contr√¥le de gestion).\\n\\nEnvironnement : PeopleSoft, Excel, VBA\\n\\n',\n",
       " 'Ing√©nieur Data / D√©veloppeur BI ‚Äì Sp√©cialisation donn√©es m√©dicales\\nEmail : jean.dupont@example.com\\nT√©l√©phone : 06 45 89 22 77\\n\\nProfil\\nData engineer exp√©riment√© dans l‚Äôexploitation, la fiabilit√© et la valorisation de donn√©es m√©dicales.\\nHabitu√© √† mod√©liser des flux de donn√©es, construire des pipelines ETL complexes sous Talend et SQL (Oracle), et √† assurer la qualit√©, la s√©curit√© et la tra√ßabilit√© des donn√©es pour des environnements analytiques et d√©cisionnels (BI, tableaux de bord, reporting).\\n\\nComp√©tences cl√©s\\nLangages : SQL (Oracle, PostgreSQL), R, Java, Scala, Julia (bases)\\nOutils ETL / Data Pipeline : Talend, Airflow, DataStage\\nBusiness Intelligence : Tableau, QlikView, Power BI\\nVersioning : Git, Bitbucket, GitHub\\nData Modeling : conception de sch√©mas, mod√©lisation de tables, int√©gration de donn√©es h√©t√©rog√®nes\\nQualit√© & S√©curit√© : validation des datasets, contr√¥les de coh√©rence, gestion des acc√®s et anonymisation\\nBonnes pratiques : documentation, revue de code, standards de d√©veloppement BI\\nAutres outils : Linux, Bash, Excel avanc√©, Jupyter, RStudio\\n\\nExp√©rience professionnelle\\n2021 ‚Äì aujourd‚Äôhui : Data Engineer ‚Äì D√©partement d‚ÄôInformation et Donn√©es M√©dicales (DIDM), H√¥pital Saint-Louis ‚Äì Paris\\nConstruction de pipelines de donn√©es pour alimenter la BI et l‚Äôanalytique.\\nMod√©lisation et structuration de flux, tables et sch√©mas de donn√©es m√©dicales.\\nD√©veloppement de datasets BI utilis√©s pour les tableaux de bord Tableau et QlikView.\\nMise en place de standards de d√©veloppement et de bonnes pratiques (Git + Talend).\\nSupport et r√©solution d‚Äôincidents sur le p√©rim√®tre data.\\nGarantir la fiabilit√© et la s√©curit√© des donn√©es selon les contraintes CNIL et RGPD.\\n2018 ‚Äì 2021 : Analyste D√©veloppeur BI ‚Äì Laboratoires Sant√© France\\nD√©veloppement d‚ÄôETL sous Talend et int√©gration Oracle.\\nMod√©lisation de l‚Äôentrep√¥t de donn√©es (sch√©ma en √©toile).\\nTableaux de bord interactifs sous Tableau et QlikView.\\nNettoyage, validation et contr√¥le qualit√© des datasets.\\n\\nFormation\\nMaster Informatique ‚Äì Sp√©cialisation Data Engineering et BI (Universit√© de Lyon)\\nCertification Talend Data Integration Advanced\\nCertification Oracle SQL Expert\\nCertification GitHub Foundations\\n\\nLangues\\nFran√ßais (natif)\\nAnglais (professionnel)\\n']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
